# Supply Chain Optimization

## ğŸ“Œ Overview
This project focuses on optimizing the supply chain using **machine learning** and **automation**. It integrates **Apache Airflow** for workflow orchestration, **MLflow** for model monitoring, and **DVC** for data versioning. The project also leverages **Docker** for containerization and reproducibility.

## ğŸš€ Features
- **Automated Workflow Orchestration** using Apache Airflow
- **Machine Learning Model Monitoring** with MLflow & DagsHub
- **Data Versioning** with DVC
- **Containerized Environment** using Docker & Conda
- **Modular Architecture** with separate environments for main processing and orchestration

## ğŸ› ï¸ Tech Stack
- **Programming Language**: Python
- **Workflow Orchestration**: Apache Airflow
- **Model Tracking**: MLflow
- **Data Versioning**: DVC
- **Containerization**: Docker
- **Virtual Environments**: Conda & venv
- **OS**: Linux

## ğŸ“‚ Project Structure
```
ğŸ“¦ supply-chain-optimization
â”œâ”€â”€ ğŸ“ main            # Core ML & data processing files (Conda env)
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ src
â”‚   â”‚   â”œâ”€â”€ data_preprocessing.py
â”‚   â”‚   â”œâ”€â”€ model_training.py
â”‚   â”‚   â”œâ”€â”€ evaluation.py
â”‚   â”œâ”€â”€ config.yaml
â”œâ”€â”€ ğŸ“ airflow         # Workflow orchestration (Python venv)
â”‚   â”œâ”€â”€ dags
â”‚   â”‚   â”œâ”€â”€ data_pipeline.py
â”‚   â”‚   â”œâ”€â”€ model_training_dag.py
â”‚   â”œâ”€â”€ airflow.cfg
â”œâ”€â”€ ğŸ“ data            # Data files (tracked with DVC)
â”œâ”€â”€ ğŸ“ models          # Trained models (logged in MLflow)
â”œâ”€â”€ README.md         # Project Documentation
```

## ğŸ”§ Installation & Setup
### 1ï¸âƒ£ Clone the Repository
```bash
git clone https://github.com/yourusername/supply-chain-optimization.git
cd supply-chain-optimization
```

### 2ï¸âƒ£ Set Up Conda Environment (Main)
```bash
conda create --name supply_chain python=3.8 -y
conda activate supply_chain
pip install -r main/requirements.txt
```

### 3ï¸âƒ£ Set Up Airflow (Orchestration)
```bash
cd airflow
python -m venv airflow_env
source airflow_env/bin/activate
pip install apache-airflow
```

### 4ï¸âƒ£ Run Docker for Containerization (Optional)
```bash
cd main
docker build -t supply-chain-optimization .
docker run -p 5000:5000 supply-chain-optimization
```

### 5ï¸âƒ£ Start Airflow Scheduler & Webserver
```bash
airflow scheduler &
airflow webserver -p 8080 &
```

## ğŸš¦ Usage
- **Trigger Airflow DAGs**: Open [Airflow UI](http://localhost:8080) and start the pipeline.
- **Monitor ML Models**: Open [DagsHub](https://dagshub.com/) or MLflow UI.
- **Manage Data Versions**: Use DVC commands like `dvc pull` & `dvc push`.

## ğŸ› ï¸ To-Do & Future Enhancements
- [ ] Implement real-time data streaming
- [ ] Improve model retraining pipeline
- [ ] Add CI/CD automation for DAG triggers

## ğŸ¤ Contribution
Feel free to fork this repository, submit issues, and contribute to improvements!

## ğŸ“œ License
This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

---

**Maintainer:** [Your Name](https://github.com/yourusername)
